use determinstic 
cfg file setup :  DATAMANAGER:
  DATALOADER:
    NUM_WORKERS: 0
    TEST:
      BATCH_SIZE: 128
      SAMPLER: SequentialSampler
    TRAIN_U:
      BATCH_SIZE: 64
      N_DOMAIN: 0
      SAME_AS_X: True
      SAMPLER: RandomSampler
    TRAIN_X:
      BATCH_SIZE: 128
      N_DOMAIN: 0
      SAMPLER: WeightRandomSampler
    VALID:
      BATCH_SIZE: 128
      N_DOMAIN: 0
      SAMPLER: SequentialSampler
  DATASET:
    AUGMENTATION:
      NAME: 
      PARAMS:
        DATASET_NAME: BCI_IV
        MAX_FIX_TRIAL: -1
        MAX_TRIAL_MUL: 3
        N_SEGMENT: 4
    DIR: task_1_final_case_1
    EA: False
    FILENAME: full_target_sleep.mat
    FILTERBANK:
      USE_FILTERBANK: False
      freq_interval: 4
    NAME: MultiDatasetV1
    ROOT: /data1/wduong_experiment_data/EEG_Dassl_Lightning/da_dataset/NeurIPS_1
    SETUP:
      INCREMENT_FOLD:
        CURRENT_INCREMENT_FOLD: 1
        END_INCREMENT_FOLD: 1
        INCREMENT_FOLD_PREFIX: increment_fold
        INCREMENT_TRAIN_SUGJECT: 0
        N_INCREMENT_FOLDS: 1
        START_INCREMENT_FOLD: 1
        START_NUM_TRAIN_SUGJECT: -1
      SHUFFLE_TRAIN_VALID_FOLD:
        CURRENT_SHUFFLE_FOLD: 1
        END_SHUFFLE_FOLD: 1
        N_SHUFFLE_FOLDS: 1
        SET_FIX_SEED: False
        SHUFFLE_FOLD_PREFIX: shuffle_fold
        SHUFFLE_SEED: []
        START_SHUFFLE_FOLD: 1
      SOURCE_DATASET_NAMES: []
      TARGET_DATASET_NAME: 
      TARGET_DATASET_NAMES: ['full_target_sleep']
      TEST_FOLD:
        CURRENT_TEST_FOLD: 1
        END_TEST_FOLD: 1
        NUM_TEST_SUBJECTS: -1
        N_TEST_FOLDS: 1
        SAME_AS_VALID: True
        START_TEST_FOLD: 1
        TEST_FOLD_PREFIX: test_fold
        TEST_SUBJECT_INDEX: []
        TRAIN_VALID_DATA_RATIO: -1
        WITHIN_SUBJECTS: False
      VALID_FOLD:
        CROSS_SUBJECTS: False
        CURRENT_VALID_FOLD: 1
        DOMAIN_CLASS_WEIGHT: True
        END_VALID_FOLD: 5
        N_VALID_FOLDS: 5
        SOURCE_DOMAIN_CLASS_WEIGHT: True
        START_VALID_FOLD: 1
        TOTAL_CLASS_WEIGHT: False
        TRAIN_DATA_RATIO: -1
        VALID_FOLD_PREFIX: valid_fold
        WITHIN_SUBJECTS: False
    TEST_DATA_FILE: 
    TEST_DIR: 
    TEST_SET_FILENAME: 
    USE_Euclidean_Aligment: False
    extra_files: ['source_sleep_0.mat', 'source_sleep_1.mat', 'source_sleep_2.mat', 'source_sleep_3.mat', 'source_sleep_4.mat']
    r_op_file: 
    source_dataset_LA: False
    target_dataset_relabelled: False
  MANAGER_TYPE: single_dataset
  RESULT_FOLDER: result_folder
DISPLAY_INFO:
  DATASET: True
  DataManager: True
  TRAINER: True
  writer: False
EXTRA_FIELDS:
  EA: False
  LA: False
  aug: no_aug
  backbone: deepsleep
  model: BaseModel
  normalize: no_norm
  source_dataset: []
  source_label_space: []
  target_dataset: full_dataset
  target_label_space: 6
INPUT:
  NO_TRANSFORM: True
  SIZE: (2, 3000)
  TRANSFORMS: []
LIGHTNING_MODEL:
  ACTIVE_LEARNING:
    USE_MODEL_UPDATE_DIR: 
    ensemble_confidence_level: -1
  COMPONENTS:
    BACKBONE:
      FREEZE: True
      NAME: deepsleep
      PARAMS:
        F1: 8
        F2: 8
        avg_pool_1: 10
        avg_pool_2: 10
        drop_prob: 0.25
        kern_length_1: 200
        kern_length_2: 100
        num_ch: 2
        samples: 3000
      PRETRAINED: False
      PRETRAINED_PATH: 
    LAST_FC:
      NAME: max_norm
      max_norm: 0.5
    LAYER:
      NAME: EEGNetConv3
      PARAMS:
        F2: 16
        avg_pool_1: 4
        avg_pool_2: 8
        drop_prob: 0.25
        samples: 256
        sep_kern_length: 16
  PRETRAIN:
    DIR: 
    USE_BEST: False
  TRAINER:
    CDAN:
      lmda: 1.0
      use_entropy: False
      use_projection: False
    DAN:
      GaussianKernel:
        alpha: [0.5, 1.0, 2.0]
        sigma: []
        track_running_stats: True
      linear: False
      lmda: 1.0
      trade_off: 1.0
    DANN:
      lmda: 1.0
    EXTRA:
      PRETRAIN_SOURCE_LOSS_RATIO: 1.0
      PRETRAIN_TARGET_LOSS_RATIO: 0.0
      SOURCE_LOSS_RATIO: 0.2
      SOURCE_PRE_TRAIN_EPOCHS: 10
      TARGET_LOSS_RATIO: 0.8
    EpiDG:
      loss_weight_epic: 0.8
      loss_weight_epif: 0.8
      loss_weight_epir: 0.8
      start_train_classifier: 35
      start_train_feature: 35
      warm_up_DS: 25
      warn_up_AGG: 35
    MLDG:
      alpha: 0.1
      inner_lr: 0.1
      num_inner_loop: 1
      num_test_subject: 1
      percent_test_subject: 0.0
    NAME: BaseModel
    PARAMS:
      pretrain: False
      pretrain_epochs: 0
LIGHTNING_TRAINER:
  CHECKPOINT:
    every_n_val_epochs: 1
    filename: best
    monitor: val_loss
    save_last: True
    save_top_k: 1
  LOGGER:
    
  early_stop:
    params:
      
    use_early_stop: False
  multiple_trainloader_mode: max_size_cycle
  num_sanity_val_steps: 0
  profiler: simple
  progress_bar_refresh_rate: 100
  stochastic_weight_avg: False
OPTIM:
  BASE_LR_MULT: 0.1
  COSINDECAY:
    LAST_EPOCH: -1
    MAX_LR: 0.01
    WARM_DROP: 1.0
    WARM_UP: 10
  GAMMA: 0.1
  LR_SCHEDULER: single_step
  MAX_EPOCH: 15
  NEW_LAYERS: ()
  OPTIMIZER:
    NAME: adam
    PARAMS:
      lr: 0.001
      weight_decay: 0.0
  SCHEDULER:
    NAME: exponential
    PARAMS:
      gamma: 1.0
  STAGED_LR: False
  STEPSIZE: (10,)
OUTPUT_DIR: /data1/wduong_experiment_data/EEG_Dassl_Lightning/NeurIPS_1/task_1_final_1/quick_ver_1_1/tune_cla/no_aug/no_norm/deepsleep_vanilla/full_dataset/model
RESUME: 
TEST:
  COMPUTE_CMAT: False
  EVALUATOR: Classification
  EVAL_FREQ: 1
  NO_TEST: False
  PER_CLASS_RESULT: True
  SPLIT: test
TRAIN:
  CHECKPOINT_FREQ: 0
  COUNT_ITER: bigger_one
  PRINT_FREQ: 10
  SAVE_HISTORY_RECORD: True
  SAVE_LAST_EPOCH: True
USE_CUDA: True
VERBOSE: True
VERSION: 1
history_dir: 
output_dir: 
Loading dataset: MultiDatasetV1
data root :  /data1/wduong_experiment_data/EEG_Dassl_Lightning/da_dataset/NeurIPS_1
dataset dir :  task_1_final_case_1
file name :  full_target_sleep.mat
r_op file path :  None
add dataset full_target_sleep into list target data 
test subject idx after split :  None
train-valid idx after split :  [0 1 2 3 4]
cross subject split for valid data
train subject after split :  [1, 2, 3, 4]
valid subject after split :  [0]
there is no test file 
train subjects :  [1, 2, 3, 4]
Train subject 1 has shape : (3187, 1, 2, 3000), with range scale (182.0,-175.92308044433594) 
Train subject 2 has shape : (3305, 1, 2, 3000), with range scale (162.62197875976562,-177.0) 
Train subject 3 has shape : (3024, 1, 2, 3000), with range scale (182.0,-193.0) 
Train subject 4 has shape : (4482, 1, 2, 3000), with range scale (199.0,-199.0) 
test subjects :  [0]
test subject 0 has shape : (2570, 1, 2, 3000), with range scale (200.0,-200.0)  
valid subjects :  [0]
valid subject 0 has shape : (2570, 1, 2, 3000), with range scale (200.0,-200.0)  
Loading trainer: BaseModel
Building model
Backbone: deepsleep
params set up :  {'kern_length_1': 200, 'kern_length_2': 100, 'num_ch': 2, 'samples': 3000, 'F1': 8, 'F2': 8, 'drop_prob': 0.25, 'avg_pool_1': 10, 'avg_pool_2': 10}
pretrain :  False
pretrain path : 
use max norm 0.5 constraint on last FC
# params: 11,086
freeze base model backbone --- 
save checkpoint keys :  dict_keys(['epoch', 'global_step', 'pytorch-lightning_version', 'state_dict', 'callbacks', 'optimizer_states', 'lr_schedulers'])
size of test loader :  1
Testing: 0it [00:00, ?it/s]in test epoch end
Testing: 100%|##########| 21/21 [00:00<00:00, 114.70it/s]
--------------------------------------------------------------------------------
DATALOADER:0 TEST RESULTS
{'class_0_acc': 0.9398496150970459,
 'class_1_acc': 0.5323275923728943,
 'class_2_acc': 0.43958136439323425,
 'class_3_acc': 0.75,
 'class_4_acc': 0.0,
 'class_5_acc': 0.20158103108406067,
 'test_F1': 0.35729771852493286,
 'test_acc': 0.5887159705162048,
 'test_classes_avg_acc': 0.4772232472896576,
 'test_loss': 0.9040741920471191}
--------------------------------------------------------------------------------
test result :  {'test_acc': 0.5887159705162048, 'test_loss': 0.9040741920471191, 'test_F1': 0.35729771852493286, 'test_classes_avg_acc': 0.4772232472896576, 'class_0_acc': 0.9398496150970459, 'class_1_acc': 0.5323275923728943, 'class_2_acc': 0.43958136439323425, 'class_3_acc': 0.75, 'class_4_acc': 0.0, 'class_5_acc': 0.20158103108406067}
Loading dataset: MultiDatasetV1
data root :  /data1/wduong_experiment_data/EEG_Dassl_Lightning/da_dataset/NeurIPS_1
dataset dir :  task_1_final_case_1
file name :  full_target_sleep.mat
r_op file path :  None
add dataset full_target_sleep into list target data 
test subject idx after split :  None
train-valid idx after split :  [0 1 2 3 4]
cross subject split for valid data
train subject after split :  [0, 2, 3, 4]
valid subject after split :  [1]
there is no test file 
train subjects :  [0, 2, 3, 4]
Train subject 0 has shape : (2570, 1, 2, 3000), with range scale (200.0,-200.0) 
Train subject 2 has shape : (3305, 1, 2, 3000), with range scale (162.62197875976562,-177.0) 
Train subject 3 has shape : (3024, 1, 2, 3000), with range scale (182.0,-193.0) 
Train subject 4 has shape : (4482, 1, 2, 3000), with range scale (199.0,-199.0) 
test subjects :  [1]
test subject 1 has shape : (3187, 1, 2, 3000), with range scale (182.0,-175.92308044433594)  
valid subjects :  [1]
valid subject 1 has shape : (3187, 1, 2, 3000), with range scale (182.0,-175.92308044433594)  
Loading trainer: BaseModel
Building model
Backbone: deepsleep
params set up :  {'kern_length_1': 200, 'kern_length_2': 100, 'num_ch': 2, 'samples': 3000, 'F1': 8, 'F2': 8, 'drop_prob': 0.25, 'avg_pool_1': 10, 'avg_pool_2': 10}
pretrain :  False
pretrain path : 
use max norm 0.5 constraint on last FC
# params: 11,086
freeze base model backbone --- 
save checkpoint keys :  dict_keys(['epoch', 'global_step', 'pytorch-lightning_version', 'state_dict', 'callbacks', 'optimizer_states', 'lr_schedulers'])
size of test loader :  1
Testing: 0it [00:00, ?it/s]Testing: 100%|##########| 25/25 [00:00<00:00, 245.75it/s]in test epoch end
Testing: 100%|##########| 25/25 [00:00<00:00, 116.91it/s]
--------------------------------------------------------------------------------
DATALOADER:0 TEST RESULTS
{'class_0_acc': 0.8394210934638977,
 'class_1_acc': 0.6602739691734314,
 'class_2_acc': 0.4147368371486664,
 'class_3_acc': 0.0,
 'class_4_acc': 0.0,
 'class_5_acc': 0.6579572558403015,
 'test_F1': 0.39621832966804504,
 'test_acc': 0.6683401465415955,
 'test_classes_avg_acc': 0.4287315011024475,
 'test_loss': 0.6944934129714966}
--------------------------------------------------------------------------------
test result :  {'test_acc': 0.6683401465415955, 'test_loss': 0.6944934129714966, 'test_F1': 0.39621832966804504, 'test_classes_avg_acc': 0.4287315011024475, 'class_0_acc': 0.8394210934638977, 'class_1_acc': 0.6602739691734314, 'class_2_acc': 0.4147368371486664, 'class_3_acc': 0.0, 'class_4_acc': 0.0, 'class_5_acc': 0.6579572558403015}
Loading dataset: MultiDatasetV1
data root :  /data1/wduong_experiment_data/EEG_Dassl_Lightning/da_dataset/NeurIPS_1
dataset dir :  task_1_final_case_1
file name :  full_target_sleep.mat
r_op file path :  None
add dataset full_target_sleep into list target data 
test subject idx after split :  None
train-valid idx after split :  [0 1 2 3 4]
cross subject split for valid data
train subject after split :  [0, 1, 3, 4]
valid subject after split :  [2]
there is no test file 
train subjects :  [0, 1, 3, 4]
Train subject 0 has shape : (2570, 1, 2, 3000), with range scale (200.0,-200.0) 
Train subject 1 has shape : (3187, 1, 2, 3000), with range scale (182.0,-175.92308044433594) 
Train subject 3 has shape : (3024, 1, 2, 3000), with range scale (182.0,-193.0) 
Train subject 4 has shape : (4482, 1, 2, 3000), with range scale (199.0,-199.0) 
test subjects :  [2]
test subject 2 has shape : (3305, 1, 2, 3000), with range scale (162.62197875976562,-177.0)  
valid subjects :  [2]
valid subject 2 has shape : (3305, 1, 2, 3000), with range scale (162.62197875976562,-177.0)  
Loading trainer: BaseModel
Building model
Backbone: deepsleep
params set up :  {'kern_length_1': 200, 'kern_length_2': 100, 'num_ch': 2, 'samples': 3000, 'F1': 8, 'F2': 8, 'drop_prob': 0.25, 'avg_pool_1': 10, 'avg_pool_2': 10}
pretrain :  False
pretrain path : 
use max norm 0.5 constraint on last FC
# params: 11,086
freeze base model backbone --- 
save checkpoint keys :  dict_keys(['epoch', 'global_step', 'pytorch-lightning_version', 'state_dict', 'callbacks', 'optimizer_states', 'lr_schedulers'])
size of test loader :  1
Testing: 0it [00:00, ?it/s]Testing: 100%|##########| 26/26 [00:00<00:00, 241.52it/s]in test epoch end
Testing: 100%|##########| 26/26 [00:00<00:00, 118.67it/s]
--------------------------------------------------------------------------------
DATALOADER:0 TEST RESULTS
{'class_0_acc': 0.9612307548522949,
 'class_1_acc': 0.3218390941619873,
 'class_2_acc': 0.6240310072898865,
 'class_3_acc': 0.8305084705352783,
 'class_4_acc': 0.7183098793029785,
 'class_5_acc': 0.6730310320854187,
 'test_F1': 0.666920006275177,
 'test_acc': 0.800000011920929,
 'test_classes_avg_acc': 0.688158392906189,
 'test_loss': 0.5626700520515442}
--------------------------------------------------------------------------------
test result :  {'test_acc': 0.800000011920929, 'test_loss': 0.5626700520515442, 'test_F1': 0.666920006275177, 'test_classes_avg_acc': 0.688158392906189, 'class_0_acc': 0.9612307548522949, 'class_1_acc': 0.3218390941619873, 'class_2_acc': 0.6240310072898865, 'class_3_acc': 0.8305084705352783, 'class_4_acc': 0.7183098793029785, 'class_5_acc': 0.6730310320854187}
Loading dataset: MultiDatasetV1
data root :  /data1/wduong_experiment_data/EEG_Dassl_Lightning/da_dataset/NeurIPS_1
dataset dir :  task_1_final_case_1
file name :  full_target_sleep.mat
r_op file path :  None
add dataset full_target_sleep into list target data 
test subject idx after split :  None
train-valid idx after split :  [0 1 2 3 4]
cross subject split for valid data
train subject after split :  [0, 1, 2, 4]
valid subject after split :  [3]
there is no test file 
train subjects :  [0, 1, 2, 4]
Train subject 0 has shape : (2570, 1, 2, 3000), with range scale (200.0,-200.0) 
Train subject 1 has shape : (3187, 1, 2, 3000), with range scale (182.0,-175.92308044433594) 
Train subject 2 has shape : (3305, 1, 2, 3000), with range scale (162.62197875976562,-177.0) 
Train subject 4 has shape : (4482, 1, 2, 3000), with range scale (199.0,-199.0) 
test subjects :  [3]
test subject 3 has shape : (3024, 1, 2, 3000), with range scale (182.0,-193.0)  
valid subjects :  [3]
valid subject 3 has shape : (3024, 1, 2, 3000), with range scale (182.0,-193.0)  
Loading trainer: BaseModel
Building model
Backbone: deepsleep
params set up :  {'kern_length_1': 200, 'kern_length_2': 100, 'num_ch': 2, 'samples': 3000, 'F1': 8, 'F2': 8, 'drop_prob': 0.25, 'avg_pool_1': 10, 'avg_pool_2': 10}
pretrain :  False
pretrain path : 
use max norm 0.5 constraint on last FC
# params: 11,086
freeze base model backbone --- 
save checkpoint keys :  dict_keys(['epoch', 'global_step', 'pytorch-lightning_version', 'state_dict', 'callbacks', 'optimizer_states', 'lr_schedulers'])
size of test loader :  1
Testing: 0it [00:00, ?it/s]in test epoch end
Testing: 100%|##########| 24/24 [00:00<00:00, 119.18it/s]
--------------------------------------------------------------------------------
DATALOADER:0 TEST RESULTS
{'class_0_acc': 0.916522741317749,
 'class_1_acc': 0.48163264989852905,
 'class_2_acc': 0.7408638000488281,
 'class_3_acc': 0.20000000298023224,
 'class_4_acc': 0.0,
 'class_5_acc': 0.8571428656578064,
 'test_F1': 0.4874725341796875,
 'test_acc': 0.8217592835426331,
 'test_classes_avg_acc': 0.5326936841011047,
 'test_loss': 0.4587961435317993}
--------------------------------------------------------------------------------
test result :  {'test_acc': 0.8217592835426331, 'test_loss': 0.4587961435317993, 'test_F1': 0.4874725341796875, 'test_classes_avg_acc': 0.5326936841011047, 'class_0_acc': 0.916522741317749, 'class_1_acc': 0.48163264989852905, 'class_2_acc': 0.7408638000488281, 'class_3_acc': 0.20000000298023224, 'class_4_acc': 0.0, 'class_5_acc': 0.8571428656578064}
Loading dataset: MultiDatasetV1
data root :  /data1/wduong_experiment_data/EEG_Dassl_Lightning/da_dataset/NeurIPS_1
dataset dir :  task_1_final_case_1
file name :  full_target_sleep.mat
r_op file path :  None
add dataset full_target_sleep into list target data 
test subject idx after split :  None
train-valid idx after split :  [0 1 2 3 4]
cross subject split for valid data
train subject after split :  [0, 1, 2, 3]
valid subject after split :  [4]
there is no test file 
train subjects :  [0, 1, 2, 3]
Train subject 0 has shape : (2570, 1, 2, 3000), with range scale (200.0,-200.0) 
Train subject 1 has shape : (3187, 1, 2, 3000), with range scale (182.0,-175.92308044433594) 
Train subject 2 has shape : (3305, 1, 2, 3000), with range scale (162.62197875976562,-177.0) 
Train subject 3 has shape : (3024, 1, 2, 3000), with range scale (182.0,-193.0) 
test subjects :  [4]
test subject 4 has shape : (4482, 1, 2, 3000), with range scale (199.0,-199.0)  
valid subjects :  [4]
valid subject 4 has shape : (4482, 1, 2, 3000), with range scale (199.0,-199.0)  
Loading trainer: BaseModel
Building model
Backbone: deepsleep
params set up :  {'kern_length_1': 200, 'kern_length_2': 100, 'num_ch': 2, 'samples': 3000, 'F1': 8, 'F2': 8, 'drop_prob': 0.25, 'avg_pool_1': 10, 'avg_pool_2': 10}
pretrain :  False
pretrain path : 
use max norm 0.5 constraint on last FC
# params: 11,086
freeze base model backbone --- 
save checkpoint keys :  dict_keys(['epoch', 'global_step', 'pytorch-lightning_version', 'state_dict', 'callbacks', 'optimizer_states', 'lr_schedulers'])
size of test loader :  1
Testing: 0it [00:00, ?it/s]Testing: 100%|##########| 36/36 [00:00<00:00, 257.96it/s]in test epoch end
Testing: 100%|##########| 36/36 [00:00<00:00, 120.91it/s]
--------------------------------------------------------------------------------
DATALOADER:0 TEST RESULTS
{'class_0_acc': 0.9381255507469177,
 'class_1_acc': 0.5756579041481018,
 'class_2_acc': 0.5630841255187988,
 'class_3_acc': 0.7777777910232544,
 'class_4_acc': 0.9054054021835327,
 'class_5_acc': 0.6972972750663757,
 'test_F1': 0.6615861058235168,
 'test_acc': 0.7766622304916382,
 'test_classes_avg_acc': 0.7428913712501526,
 'test_loss': 0.5797662734985352}
--------------------------------------------------------------------------------
test result :  {'test_acc': 0.7766622304916382, 'test_loss': 0.5797662734985352, 'test_F1': 0.6615861058235168, 'test_classes_avg_acc': 0.7428913712501526, 'class_0_acc': 0.9381255507469177, 'class_1_acc': 0.5756579041481018, 'class_2_acc': 0.5630841255187988, 'class_3_acc': 0.7777777910232544, 'class_4_acc': 0.9054054021835327, 'class_5_acc': 0.6972972750663757}
current result before convert excel :  [{'test_acc': 0.5887159705162048, 'test_loss': 0.9040741920471191, 'test_F1': 0.35729771852493286, 'test_classes_avg_acc': 0.4772232472896576, 'class_0_acc': 0.9398496150970459, 'class_1_acc': 0.5323275923728943, 'class_2_acc': 0.43958136439323425, 'class_3_acc': 0.75, 'class_4_acc': 0.0, 'class_5_acc': 0.20158103108406067, 'test_fold': 'test_fold_1', 'valid_fold': 'valid_fold_1', 'epoch': 12}, {'test_acc': 0.6683401465415955, 'test_loss': 0.6944934129714966, 'test_F1': 0.39621832966804504, 'test_classes_avg_acc': 0.4287315011024475, 'class_0_acc': 0.8394210934638977, 'class_1_acc': 0.6602739691734314, 'class_2_acc': 0.4147368371486664, 'class_3_acc': 0.0, 'class_4_acc': 0.0, 'class_5_acc': 0.6579572558403015, 'test_fold': 'test_fold_1', 'valid_fold': 'valid_fold_2', 'epoch': 8}, {'test_acc': 0.800000011920929, 'test_loss': 0.5626700520515442, 'test_F1': 0.666920006275177, 'test_classes_avg_acc': 0.688158392906189, 'class_0_acc': 0.9612307548522949, 'class_1_acc': 0.3218390941619873, 'class_2_acc': 0.6240310072898865, 'class_3_acc': 0.8305084705352783, 'class_4_acc': 0.7183098793029785, 'class_5_acc': 0.6730310320854187, 'test_fold': 'test_fold_1', 'valid_fold': 'valid_fold_3', 'epoch': 11}, {'test_acc': 0.8217592835426331, 'test_loss': 0.4587961435317993, 'test_F1': 0.4874725341796875, 'test_classes_avg_acc': 0.5326936841011047, 'class_0_acc': 0.916522741317749, 'class_1_acc': 0.48163264989852905, 'class_2_acc': 0.7408638000488281, 'class_3_acc': 0.20000000298023224, 'class_4_acc': 0.0, 'class_5_acc': 0.8571428656578064, 'test_fold': 'test_fold_1', 'valid_fold': 'valid_fold_4', 'epoch': 2}, {'test_acc': 0.7766622304916382, 'test_loss': 0.5797662734985352, 'test_F1': 0.6615861058235168, 'test_classes_avg_acc': 0.7428913712501526, 'class_0_acc': 0.9381255507469177, 'class_1_acc': 0.5756579041481018, 'class_2_acc': 0.5630841255187988, 'class_3_acc': 0.7777777910232544, 'class_4_acc': 0.9054054021835327, 'class_5_acc': 0.6972972750663757, 'test_fold': 'test_fold_1', 'valid_fold': 'valid_fold_5', 'epoch': 2}]
